```{r instalaciones_paquetes, echo=FALSE}


```

```{r cargar_librerias, echo=FALSE, message=FALSE, warning=FALSE}
    library(caret)
    library(tree)
    library(mlr)
    library(mlr3)
    library(mlr3verse)
    library(rpart)
    library(rpart.plot)
    library(Metrics)
    library(randomForest)
    library(dplyr)
    library(ParamHelpers)
    library(magrittr)
    library(ggplot2)
    library(MLmetrics)
```

# 1. Lectura Dataset
```{r recoleccion_de_data}
    datos <- read.csv("train.csv")
    datos <- datos[ , !(names(datos) %in% c("Id","YrSold","MoSold","GarageYrBlt","MSSubClass","YearBuilt"))]

    Cuantitativas <- c("SalePrice", "LotFrontage", "LotArea", "OverallQual", "OverallCond", "MasVnrArea", "BsmtFinSF1", "BsmtFinSF2", "BsmtUnfSF", "TotalBsmtSF", "X1stFlrSF", "X2ndFlrSF", "LowQualFinSF", "GrLivArea", "BsmtFullBath", "BsmtHalfBath", "FullBath", "HalfBath", "BedroomAbvGr", "KitchenAbvGr", "TotRmsAbvGrd", "Fireplaces", "GarageCars", "GarageArea", "WoodDeckSF", "OpenPorchSF", "EnclosedPorch", "X3SsnPorch", "ScreenPorch", "PoolArea", "MiscVal")
    df_cuantitativas <- datos[Cuantitativas]
```

```{r normalizar_datos}
    datos$LotFrontage[is.na(datos$LotFrontage)] <- median(datos$LotFrontage, na.rm = TRUE)
    datos$MasVnrArea[is.na(datos$MasVnrArea)] <- median(datos$MasVnrArea, na.rm = TRUE)
    datos <- datos[ , !(names(datos) %in% c("Alley", "PoolQC", "Fence", "MiscFeature","FireplaceQu"))]

    df_cuantitativas <- datos[Cuantitativas] #Tras los cambios de Na´s
    df_norm <- mutate_if(datos, is.numeric, scale)
    df_cualitativas <- df_norm[ , !(names(df_norm) %in% Cuantitativas)]

    for (i in 1:ncol(df_cualitativas)) {
         df_norm[,i] <- ifelse(is.na(df_norm[,i]), "Desconocido", df_norm[,i])
    }

    df_norm <- df_norm %>% mutate_at(colnames(df_cualitativas), function(x) as.factor(x))

```


# 1.1 Dividir el dataset en train y test
```{r split_data }
    set.seed(123)
    porcentaje<-0.7
    corte <- sample(nrow(df_norm),nrow(df_norm)*porcentaje)
    train<-df_norm[corte,]
    test<-df_norm[-corte,]
```

# 1.2 Elaborar arbol de regresion
```{r crear_modelo}
    modelo_arbol <- rpart(SalePrice ~., data = train)
    rpart.plot(modelo_arbol)
```

# 1.3 Predicciones
```{r predicciones , warning=FALSE, message=FALSE}
    predicciones <- predict(modelo_arbol, newdata = test)
    SSE <- sum((predicciones - test$SalePrice) ^ 2)
    TSS <- sum((test$SalePrice - mean(test$SalePrice)) ^ 2)
    R2 <- 1 - SSE / TSS

```
El R^2 de las predicciones y los valores reales fue de `r R2` el cual es un valor bajo ya que un modelo se considera aceptable si tiene un R^2 mayor a 0.75.

# 1.4 Haga al menos 3 modelos más con diferentes profundidades y compare los resultados
```{r multiple_trees}

    modelo1 <- rpart(SalePrice ~., data = train, maxdepth = 3)
    rpart.plot(modelo1)

    predicciones <- predict(modelo1, newdata = test)
    SSE <- sum((predicciones - test$SalePrice) ^ 2)
    TSS <- sum((test$SalePrice - mean(test$SalePrice)) ^ 2)
    R2m1 <- 1 - SSE / TSS
    R2m1

    modelo2 <- rpart(SalePrice ~., data = train, maxdepth = 10)
    rpart.plot(modelo2)

    predicciones <- predict(modelo2, newdata = test)
    SSE <- sum((predicciones - test$SalePrice) ^ 2)
    TSS <- sum((test$SalePrice - mean(test$SalePrice)) ^ 2)
    R2m2 <- 1 - SSE / TSS
    R2m2

    modelo3 <- rpart(SalePrice ~., data = train, maxdepth = 2)
    rpart.plot(modelo3)

    predicciones <- predict(modelo3, newdata = test)
    SSE <- sum((predicciones - test$SalePrice) ^ 2)
    TSS <- sum((test$SalePrice - mean(test$SalePrice)) ^ 2)
    R2m3 <- 1 - SSE / TSS
    R2m3

```
Vemos que de los 3 nuevos modelos el que mejor R^2 lo tiene el modelo 2 con un R^2 de `r R2m2` con profundidad de 10, pero cabe destacar que el modelo de regresion lineal multivariable tiene un R^2 de 0.7, por lo que el modelo de arboles de regresion no lo hizo mejor que el modelo de regresion lineal multivariable. Además que el de profundidad 5 el de la sección **1.3** tuvo el mismo desempeño. Por lo que consideramos que podemos quedarnos con el modelo de profundidad 5. Esto se puede deber a que al momento de realizar la poda quedan pocos nodos y no se puede tener una profundiad de 10.


# 1.5 Compare los resultados con el modelo de regresión lineal de la hoja anterior
El R^2 de las predicciones y los valores reales fue de `r R2` el cual es un valor muy bajo, pero cabe destacar que en la hoja de trabajo anterior el {R2} fue de 0.7 para el modelo de regresion lineal multivariable, Por lo que el modelo de arboles de regresion no lo hizo mejor que el modelo de regresion lineal multivariable. Y un resultado muy similar al modelo de regresion lineal univariable.


# 1.6 Creacion de nueva variable Classification
```{r clasificacion}
    salePrices <- df_norm$SalePrice
    q1 <- quantile(df_norm$SalePrice, 0.33)
    q2 <- quantile(df_norm$SalePrice, 0.66)
    df_norm$Classification <- sapply(df_norm$SalePrice, function(x) ifelse(x < q1, "Economicas", ifelse(x < q2, "Intermedias", "Caras")))
    df_norm$Classification <- factor(df_norm$Classification)
```
Para poder crear la nueva variable Classification, primero se obtuvieron los cuartiles de la variable SalePrice , y se crearon 3 categorias, las cuales son Economicas, Intermedias y Caras. Luego se creó una nueva variable Classification, la cual se llenó con la función sapply, la cual recorre cada valor de la variable SalePrice y dependiendo del valor de la variable SalePrice, se le asigna la categoria correspondiente. Por ultimo se convirtió la variable Classification a factor.


# 1.7 Creacion de nuevo modelo Arbol de clasificacion
```{r new_model}
    df_norm_w_SP <- df_norm[ , !(names(df_norm) %in% c("SalePrice"))]
    df_norm_w_SP <- df_norm_w_SP[ ,c("Classification","Neighborhood","OverallQual","LotFrontage","MSZoning") ]
    
    baratas <- df_norm_w_SP[df_norm_w_SP$Classification == "Economicas",]
    intermedias <- df_norm_w_SP[df_norm_w_SP$Classification == "Intermedias",]
    caras <- df_norm_w_SP[df_norm_w_SP$Classification == "Caras",]

    n_baratas <- nrow(baratas)
    n_intermedias <- nrow(intermedias)
    n_caras <- nrow(caras)

    n_train_baratas <- round(n_baratas * 0.7)
    n_train_intermedias <- round(n_intermedias * 0.7)
    n_train_caras <- round(n_caras * 0.7)

    # Muestrear el 70% de cada conjunto de casas de forma aleatoria
    train_baratas <- baratas[sample(n_baratas, n_train_baratas), ]
    train_intermedias <- intermedias[sample(n_intermedias, n_train_intermedias), ]
    train_caras <- caras[sample(n_caras, n_train_caras), ]

    # Combinar los conjuntos de entrenamiento
    train2 <- rbind(train_baratas, train_intermedias, train_caras)

    # Obtener los conjuntos de prueba como los elementos restantes
    test2 <- df_norm_w_SP[!rownames(df_norm_w_SP) %in% rownames(train), ]
    
    modelo4<- rpart(Classification~.,train2,method = "class",maxdepth=4)
    rpart.plot(modelo4)


```
Debido a que tenemos 3 posibles valores a clasificar, debebos asegurarnos que el modelo tenga sufuciente datos de los 3 valores para poder predecir. Es por ello que estratificcamos la data para poder distribuirla en train y test.

# 1.8 Eficiencia el modelo para predecir la variable Classification
```{r predict}
    ypred <- predict(modelo4, newdata = test2)
    ypred<-apply(ypred, 1, function(x) colnames(ypred)[which.max(x)])
    ypred <- factor(ypred)

    recall_score <- Recall(test2$Classification, ypred,positive = c("Caras","Intermedias","Economicas"))

```
El modelo tuvo una Recall de `r recall_score`, lo cual es un valor muy bueno para un modelo de clasificacion. A continuación veremos la matriz de confusion para ver que tan bien se comporta el modelo.


# 1.9 Eficiencia a partir de la matriz de confusion
```{r matriz de confusion}
    confusionMatrix(ypred, test2$Classification)

```
Como podemos ver en la matriz de confusion el modelo tiene problemas para predecir las casas Intermedias, pero en general el modelo tiene un buen desempeño.
# 1.10 Entrenar modelo por validacion cruzada
```{r cross_validation , warning=FALSE}
   
    train_without_pred_variable <- subset(train2, select = -Classification)
    ct <- trainControl(method = "cv",number=10, verboseIter=T)
    modelo3 <- caret::train(train_without_pred_variable, train2$Classification, trControl = ct, method="rpart")

    y3pred <- predict(modelo3, newdata = test)

    recall_score <- Recall(test2$Classification, y3pred,positive = c("Caras","Intermedias","Economicas"))
```
Luego del Crossvalidation podemos ver que el modelo tiene un buen desempeño con los valores del test, teniendo un Recall de `r recall_score`.

# 1.10 Eficiencia a partir de la matriz de confusion Cross Validation
```{r matriz de confusion2}
    confusionMatrix(y3pred, test2$Classification)

```
Como podemos ver en la matriz de confusion el modelo tiene problemas para predecir las casas Intermedias, pero en general el modelo tiene un buen desempeño. Es la misma matriz de confusión pues es el mismo modelo.

# 1.11 Creando nuevos modelos cambiando profundidad 
```{r nuevos_modelos_con_profundidad, message=FALSE, warning=FALSE}
    getParamSet("classif.rpart")
    clasificador <- makeClassifTask(data=train2, target = "Classification")
    tablaParametros<-makeParamSet(makeDiscreteParam("maxdepth",values=1:15))
    controlGrid <- makeTuneControlGrid()
    cv <- makeResampleDesc("CV",iters=3L)
    metrica <- acc
    set.seed(456)
    dt_tuneparam <- tuneParams(learner = "classif.rpart",
      task = clasificador,
      resampling = cv,
      measures = metrica,
      par.set=tablaParametros,
      control=controlGrid,
      show.info=T)
    result_hyperparam <- generateHyperParsEffectData(dt_tuneparam, partial.dep = TRUE)

    ggplot(
    data = result_hyperparam$data,
    aes(x = maxdepth, y=acc.test.mean)
    ) + geom_line(color = 'darkblue')

    best_parameters = setHyperPars(
    makeLearner("classif.rpart"), 
    par.vals = dt_tuneparam$x
    )

    best_model = train(best_parameters, clasificador)
    # test <- df_norm[-rownames(train),]

    d.tree.mlr.test <- makeClassifTask(
      data=test2, 
      target="Classification"
    )
    results <- predict(best_model, task = d.tree.mlr.test)$data
    confusionMatrix(results$truth, results$response)
    
```
El modelo que muestra un mejor desempeño es el que tiene una profundidad de 5, el cual podemos ver en la grafíca como es el punto más alto de la gráfica y luego baja y se estabilidad el desempeño del modelo.

# 1.12 Utilizando Random Forest Classification
```{r random_forest}
    modeloRF <- randomForest(Classification~.,train2,na.action = na.omit)
    ypred <- predict(modeloRF,newdata = test2)
    ypred <- factor(ypred)

    recall_score <- Recall(test2$Classification, ypred,positive = c("Caras","Intermedias","Economicas"))

    confusionMatrix(ypred,test2$Classification)

```

El modelo de RandomForest obtuvo un recall de `r recall_score` el cual es el mejor valor que se ha obtenido durante toda la hoja. Esto se puede deber a que cuenta con más arboles para poder predecir la variable Classification.


# 1.12.2 Utilizando Random Forest Classification con Cross Validation
```{r random_forest_cross_validation}

    train_without_pred_variable <- subset(train2, select = -Classification)
    ct <- trainControl(method = "cv",number=10, verboseIter=T)
    modeloRF <- caret::train(train_without_pred_variable, train2$Classification, trControl = ct, method="rf")

    y3pred <- predict(modeloRF, newdata = test)

    recall_score <- Recall(test2$Classification, y3pred,positive = c("Caras","Intermedias","Economicas"))

    confusionMatrix(y3pred,test2$Classification)

```
Cross validation nos muestra que el modelo tiene un buen desempeño con los valores del test, teniendo un Recall de `r recall_score`. con una cantidad de 76 arboles.

# 1.12.3 Tuneo de parametros para Random Forest
```{r tuneo_parametros_random_forest, warning=FALSE, message=FALSE}
    getParamSet("classif.randomForest")
    clasificador <- makeClassifTask(data=train2, target = "Classification")
    tablaParametros<-makeParamSet(makeDiscreteParam("ntree",values=1:100))
    controlGrid <- makeTuneControlGrid()
    cv <- makeResampleDesc("CV",iters=3L)
    metrica <- acc
    set.seed(456)
    dt_tuneparam <- tuneParams(learner = "classif.randomForest",
      task = clasificador,
      resampling = cv,
      measures = metrica,
      par.set=tablaParametros,
      control=controlGrid,
      show.info=T)
    result_hyperparam <- generateHyperParsEffectData(dt_tuneparam, partial.dep = TRUE)

    ggplot(
    data = result_hyperparam$data,
    aes(x = ntree, y=acc.test.mean)
    ) + geom_line(color = 'darkblue')

    best_parameters = setHyperPars(
    makeLearner("classif.randomForest"), 
    par.vals = dt_tuneparam$x
    )

    best_model = train(best_parameters, clasificador)

    d.tree.mlr.test <- makeClassifTask(
      data=test2, 
      target="Classification"
    )
    results <- predict(best_model, task = d.tree.mlr.test)$data
    confusionMatrix(results$truth, results$response)
    
```
Como podemos ver en la grafica la mejor cantidad de arboles es 75-76, pues son los que presentan el mejor desempeño.